# ğŸ” Advanced RAG Debug Guide

## ğŸš¨ **Váº¥n Äá» ÄÃ£ PhÃ¡t Hiá»‡n**

Sau khi kiá»ƒm tra luá»“ng Advanced RAG, tÃ´i Ä‘Ã£ phÃ¡t hiá»‡n má»™t sá»‘ váº¥n Ä‘á» nghiÃªm trá»ng:

### **1. Error Handling KhÃ´ng Äáº§y Äá»§**
- âŒ KhÃ´ng cÃ³ try-catch cho cÃ¡c async operations
- âŒ KhÃ´ng cÃ³ fallback khi embedding service fail
- âŒ KhÃ´ng cÃ³ timeout protection
- âŒ KhÃ´ng cÃ³ validation cho input data

### **2. Performance Issues**
- âŒ Semantic clustering táº¡o quÃ¡ nhiá»u embedding calls
- âŒ Multi-hop reasoning cÃ³ thá»ƒ timeout
- âŒ KhÃ´ng cÃ³ limit cho sá»‘ lÆ°á»£ng chunks
- âŒ KhÃ´ng cÃ³ caching mechanism

### **3. Data Validation Issues**
- âŒ KhÃ´ng kiá»ƒm tra null/undefined values
- âŒ KhÃ´ng validate embedding format
- âŒ KhÃ´ng handle missing chunks gracefully

## ğŸ”§ **Giáº£i PhÃ¡p ÄÃ£ Triá»ƒn Khai**

### **1. Advanced RAG Fixed Version**
Táº¡o file `backend/services/advancedRAGFixed.js` vá»›i:
- âœ… **Comprehensive error handling**
- âœ… **Timeout protection**
- âœ… **Data validation**
- âœ… **Fallback mechanisms**
- âœ… **Performance optimizations**

### **2. Enhanced Controller**
Cáº­p nháº­t `backend/controllers/advancedChatController.js`:
- âœ… **Try-catch cho má»i bÆ°á»›c**
- âœ… **Timeout protection cho LLM calls**
- âœ… **Fallback responses**
- âœ… **Better error logging**

### **3. Debug Tools**
Táº¡o `backend/test/advancedRAGDebug.js`:
- âœ… **Step-by-step testing**
- âœ… **Performance monitoring**
- âœ… **Error identification**
- âœ… **Database validation**

## ğŸš€ **CÃ¡ch Debug Advanced RAG**

### **1. Cháº¡y Debug Script**
```bash
cd backend
node test/advancedRAGDebug.js
```

### **2. Kiá»ƒm Tra Logs**
```bash
# Backend logs
tail -f backend/logs/advanced-rag.log

# Database logs
tail -f backend/logs/database.log
```

### **3. Test API Endpoint**
```bash
curl -X POST http://localhost:3001/advanced-chat/advanced-chat \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "message": "So sÃ¡nh NLP vÃ  Machine Learning",
    "model": "gpt-4o"
  }'
```

## ğŸ“Š **Debug Checklist**

### **Database Issues**
- [ ] Database connection working
- [ ] Knowledge chunks exist
- [ ] Embeddings are valid
- [ ] Indexes are created

### **Embedding Service**
- [ ] Embedding service running
- [ ] API endpoint accessible
- [ ] Response format correct
- [ ] Rate limits not exceeded

### **Advanced RAG Pipeline**
- [ ] Multi-stage retrieval working
- [ ] Semantic clustering successful
- [ ] Multi-hop reasoning functional
- [ ] Context fusion working
- [ ] LLM call successful

## ğŸ› **Common Issues & Solutions**

### **Issue 1: "No chunks retrieved"**
**Cause**: Database empty or embedding service down
**Solution**: 
```bash
# Check database
SELECT COUNT(*) FROM knowledge_chunks;

# Check embedding service
curl http://localhost:1234/v1/embeddings
```

### **Issue 2: "Embedding service error"**
**Cause**: Embedding service not running
**Solution**:
```bash
# Start embedding service
cd embedding-service
python -m uvicorn main:app --port 1234
```

### **Issue 3: "LLM call timeout"**
**Cause**: Context too long or LLM service slow
**Solution**:
- Reduce maxChunks
- Implement context truncation
- Add retry mechanism

### **Issue 4: "Semantic clustering failed"**
**Cause**: Too many embedding calls
**Solution**:
- Limit chunks to 10
- Use existing embeddings
- Implement caching

## ğŸ” **Debug Commands**

### **1. Test Database**
```sql
-- Check chunks count
SELECT COUNT(*) FROM knowledge_chunks;

-- Check embeddings
SELECT id, title, LENGTH(embedding) as emb_len 
FROM knowledge_chunks 
WHERE embedding IS NOT NULL 
LIMIT 5;

-- Check recent chunks
SELECT * FROM knowledge_chunks 
ORDER BY created_at DESC 
LIMIT 5;
```

### **2. Test Embedding Service**
```bash
# Test embedding endpoint
curl -X POST http://localhost:1234/v1/embeddings \
  -H "Content-Type: application/json" \
  -d '{"input": "test", "model": "text-embedding-nomic-embed-text-v1.5"}'
```

### **3. Test Advanced RAG**
```bash
# Run debug script
cd backend
node test/advancedRAGDebug.js

# Check logs
tail -f logs/advanced-rag.log
```

## ğŸ“ˆ **Performance Monitoring**

### **1. Response Time Targets**
- **Simple questions**: < 2 seconds
- **Complex questions**: < 10 seconds
- **Multi-hop reasoning**: < 15 seconds

### **2. Resource Usage**
- **Memory**: < 500MB
- **CPU**: < 80%
- **Database connections**: < 10

### **3. Error Rates**
- **Embedding errors**: < 5%
- **LLM timeouts**: < 2%
- **Database errors**: < 1%

## ğŸ¯ **Testing Scenarios**

### **Scenario 1: Simple Question**
```
Question: "NLP lÃ  gÃ¬?"
Expected: Fast response, 3-5 chunks, basic RAG
```

### **Scenario 2: Complex Question**
```
Question: "So sÃ¡nh NLP vÃ  Machine Learning, vÃ  giáº£i thÃ­ch má»‘i quan há»‡ giá»¯a chÃºng trong viá»‡c xÃ¢y dá»±ng chatbot"
Expected: Advanced RAG, 8-15 chunks, reasoning chains
```

### **Scenario 3: Edge Cases**
```
Question: "What is the meaning of life?"
Expected: Graceful fallback, no chunks found
```

## ğŸš€ **Optimization Tips**

### **1. Reduce Embedding Calls**
```javascript
// Use existing embeddings instead of generating new ones
const existingEmbedding = chunk.embedding || await getEmbedding(chunk.content);
```

### **2. Implement Caching**
```javascript
// Cache embeddings for similar chunks
const cacheKey = `embedding_${chunk.content.substring(0, 100)}`;
```

### **3. Limit Context Length**
```javascript
// Truncate context if too long
if (fusedContext.length > 8000) {
  fusedContext = fusedContext.substring(0, 8000) + '...';
}
```

## ğŸ‰ **Káº¿t Quáº£**

Sau khi Ã¡p dá»¥ng cÃ¡c fixes:

### **TrÆ°á»›c (Broken)**
- âŒ Crashes on complex questions
- âŒ No error handling
- âŒ Timeout issues
- âŒ Poor performance

### **Sau (Fixed)**
- âœ… **Robust error handling**
- âœ… **Timeout protection**
- âœ… **Fallback mechanisms**
- âœ… **Better performance**
- âœ… **Comprehensive logging**

**Advanced RAG giá» Ä‘Ã¢y hoáº¡t Ä‘á»™ng á»•n Ä‘á»‹nh vÃ  cÃ³ thá»ƒ xá»­ lÃ½ cÃ¢u há»i phá»©c táº¡p!** ğŸš€
