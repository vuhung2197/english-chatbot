import pool from '../db.js';
import { getEmbedding } from '../services/embeddingVector.js';
import { retrieveTopChunks } from '../services/rag_retrieve.js';
import { hashQuestion } from '../utils/hash.js';
import { StatusCodes } from 'http-status-codes';
import '../bootstrap/env.js';
import axios from 'axios';

/**
 * Chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n AI tr·∫£ l·ªùi th√†nh Markdown gi·ªëng ChatGPT.
 * - C√¢u ƒë·∫ßu ti√™n in ƒë·∫≠m.
 * - Gi·ªØ nguy√™n ƒëo·∫°n vƒÉn n·∫øu d√†i.
 * - Danh s√°ch ch·ªâ √°p d·ª•ng n·∫øu vƒÉn b·∫£n r√µ r√†ng l√† li·ªát k√™.
 */
function toMarkdown(text) {
  if (!text) return '';

  const paragraphs = text.split(/\n{2,}/); // T√°ch c√°c ƒëo·∫°n
  const firstPara = paragraphs.shift()?.trim();
  let markdown = '';

  // B1: C√¢u ƒë·∫ßu ti√™n in ƒë·∫≠m
  if (firstPara) {
    const sentences = firstPara.split(/(?<=\.)\s+/);
    const firstSentence = sentences.shift();
    markdown += `**${firstSentence.trim()}**\n\n`;
    if (sentences.length) {
      markdown += `${sentences.join(' ')}\n\n`;
    }
  }

  // B2: Duy·ªát c√°c ƒëo·∫°n c√≤n l·∫°i
  for (let para of paragraphs) {
    para = para.trim();
    if (!para) continue;

    const isList =
      para.startsWith('- ') ||
      para.startsWith('* ') ||
      /^[‚Ä¢\-+]\s/.test(para) ||
      (/(,|\.)\s/.test(para) && para.length < 200);

    if (isList) {
      // T√°ch theo d·∫•u ch·∫•m, ph·∫©y n·∫øu l√† danh s√°ch r·ªùi r·∫°c
      const points = para
        .split(/(?:^|\n)[‚Ä¢\-+*]?\s*/)
        .map((p) => p.trim())
        .filter((p) => p.length > 0);
      points.forEach((point) => {
        markdown += `- ${point}\n`;
      });
      markdown += '\n';
    } else {
      markdown += `${para}\n\n`;
    }
  }

  return markdown.trim();
}

/**
 * X·ª≠ l√Ω API chat ch√≠nh s·ª≠ d·ª•ng thu·∫ßn RAG.
 * - Nh·∫≠n message t·ª´ ng∆∞·ªùi d√πng.
 * - T·∫°o embedding cho c√¢u h·ªèi.
 * - T√¨m ki·∫øm c√°c chunks li√™n quan nh·∫•t.
 * - G·ªçi OpenAI ƒë·ªÉ sinh c√¢u tr·∫£ l·ªùi d·ª±a tr√™n context ƒë√£ ch·ªçn.
 * - Ghi log c√°c c√¢u h·ªèi ch∆∞a tr·∫£ l·ªùi ƒë∆∞·ª£c.
 * @param {object} req - ƒê·ªëi t∆∞·ª£ng request Express
 * @param {object} res - ƒê·ªëi t∆∞·ª£ng response Express
 */
export async function chat(req, res) {
  const { message, model } = req.body;
  const userId = req.user?.id;

  if (!message)
    return res.status(StatusCodes.BAD_REQUEST).json({ reply: 'No message!' });

  try {
    let context = '';
    let isAnswered = true;
    const systemPrompt = 'B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n nghi·ªáp, tr·∫£ l·ªùi ng·∫Øn g·ªçn, ch√≠nh x√°c.';

    // üìö S·ª≠ d·ª•ng RAG (Retrieval-Augmented Generation)
    let embedding;
    try {
      embedding = await getEmbedding(message);
    } catch (error) {
      console.error('‚ùå L·ªói t·∫°o embedding:', error);
      isAnswered = false;
      if (userId) {
        await pool.execute(
          'INSERT INTO user_questions (user_id, question, is_answered) VALUES (?, ?, ?)',
          [userId, message, false]
        );
      }
      return res.json({ reply: 'Kh√¥ng th·ªÉ t√≠nh embedding c√¢u h·ªèi!' });
    }

    const chunks = await retrieveTopChunks(embedding);
    if (!chunks.length) {
      isAnswered = false;
      await logUnanswered(message);
      if (userId) {
        await pool.execute(
          'INSERT INTO user_questions (user_id, question, is_answered) VALUES (?, ?, ?)',
          [userId, message, false]
        );
      }
      return res.json({
        reply: 'T√¥i ch∆∞a c√≥ ki·∫øn th·ª©c ph√π h·ª£p ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y.',
      });
    }

    context = chunks
      .map((c) => `Ti√™u ƒë·ªÅ: ${c.title}\nN·ªôi dung: ${c.content}`)
      .join('\n---\n');

    // üß† G·ªçi GPT
    const t0 = Date.now();
    const reply = await askChatGPT(message, context, systemPrompt, model);
    const t1 = Date.now();
    console.log('‚è±Ô∏è Th·ªùi gian g·ªçi OpenAI:', t1 - t0, 'ms');

    // ‚úÖ Ghi l·ªãch s·ª≠
    if (userId) {
      await pool.execute(
        'INSERT INTO user_questions (user_id, question, bot_reply, is_answered) VALUES (?, ?, ?, ?)',
        [userId, message, reply, isAnswered]
      );
    }

    res.json({ 
      reply: toMarkdown(reply),
      chunks_used: chunks.map(c => ({
        id: c.id,
        title: c.title,
        content: c.content.substring(0, 200) + (c.content.length > 200 ? '...' : ''),
        score: c.score,
        source: c.source || 'unknown'
      })),
      metadata: {
        total_chunks: chunks.length,
        processing_time: t1 - t0,
        model_used: model.name || 'gpt-4o',
        context_length: context.length
      }
    });
  } catch (err) {
    console.error('‚ùå L·ªói x·ª≠ l√Ω:', err);
    res.json({ reply: 'Bot ƒëang b·∫≠n, vui l√≤ng th·ª≠ l·∫°i sau!' });
  }
}

/**
 * Ghi log c√°c c√¢u h·ªèi ch∆∞a tr·∫£ l·ªùi ƒë∆∞·ª£c v√†o b·∫£ng unanswered_questions.
 * N·∫øu c√¢u h·ªèi ƒë√£ t·ªìn t·∫°i (theo hash), s·∫Ω kh√¥ng ghi tr√πng.
 * @param {string} question - C√¢u h·ªèi ch∆∞a tr·∫£ l·ªùi ƒë∆∞·ª£c t·ª´ ng∆∞·ªùi d√πng
 */
async function logUnanswered(question) {
  try {
    const hash = hashQuestion(question);
    const [rows] = await pool.execute(
      'SELECT 1 FROM unanswered_questions WHERE hash = ? LIMIT 1',
      [hash]
    );
    if (rows.length === 0) {
      await pool.execute(
        'INSERT INTO unanswered_questions (question, hash, created_at) VALUES (?, ?, NOW())',
        [question, hash]
      );
    }
  } catch (e) {
    console.warn('‚ö†Ô∏è Kh√¥ng th·ªÉ ghi log unanswered:', e.message);
  }
}

/**
 * API l·∫•y l·ªãch s·ª≠ chat g·∫ßn nh·∫•t.
 * Tr·∫£ v·ªÅ 50 b·∫£n ghi m·ªõi nh·∫•t t·ª´ b·∫£ng chat_history.
 * @param {object} req - ƒê·ªëi t∆∞·ª£ng request Express
 * @param {object} res - ƒê·ªëi t∆∞·ª£ng response Express
 */
export async function history(req, res) {
  const userId = req.user?.id;

  if (!userId)
    return res
      .status(StatusCodes.UNAUTHORIZED)
      .json({ error: 'Ch∆∞a ƒëƒÉng nh·∫≠p' });

  try {
    const [rows] = await pool.execute(
      `SELECT id, question, bot_reply, is_answered, created_at 
       FROM user_questions 
       WHERE user_id = ? 
       ORDER BY created_at DESC 
       LIMIT 50`,
      [userId]
    );
    res.json(rows);
  } catch (err) {
    console.error('‚ùå L·ªói khi l·∫•y l·ªãch s·ª≠ c√¢u h·ªèi:', err);
    res.status(500).json({ error: 'L·ªói server' });
  }
}

/**
 * API g·ª£i √Ω t·ª´ ti·∫øng Anh cho autocomplete.
 * Tr·∫£ v·ªÅ t·ªëi ƒëa 10 t·ª´ b·∫Øt ƒë·∫ßu b·∫±ng query t·ª´ b·∫£ng dictionary.
 * @param {object} req - ƒê·ªëi t∆∞·ª£ng request Express
 * @param {object} res - ƒê·ªëi t∆∞·ª£ng response Express
 */
export async function suggest(req, res) {
  const query = req.query.query?.trim().toLowerCase();
  if (!query) return res.json([]);
  const [rows] = await pool.execute(
    'SELECT DISTINCT word_en FROM dictionary WHERE word_en LIKE ? ORDER BY word_en LIMIT 10',
    [`${query}%`]
  );
  res.json(rows.map((row) => row.word_en));
}

/**
 * X√≥a m·ªôt c√¢u h·ªèi kh·ªèi l·ªãch s·ª≠ chat c·ªßa ng∆∞·ªùi d√πng hi·ªán t·∫°i theo id.
 * Ch·ªâ x√≥a n·∫øu c√¢u h·ªèi thu·ªôc v·ªÅ user ƒëang ƒëƒÉng nh·∫≠p.
 * @param {object} req - ƒê·ªëi t∆∞·ª£ng request Express
 * @param {object} res - ƒê·ªëi t∆∞·ª£ng response Express
 */
export async function deleteHistoryItem(req, res) {
  const { id } = req.params;
  const userId = req.user.id;

  if (!id || !userId) {
    return res
      .status(400)
      .json({ message: 'Thi·∫øu ID ho·∫∑c th√¥ng tin ng∆∞·ªùi d√πng.' });
  }

  try {
    const [result] = await pool.execute(
      'DELETE FROM user_questions WHERE id = ? AND user_id = ?',
      [id, userId]
    );

    if (result.affectedRows === 0) {
      return res
        .status(404)
        .json({ message: 'Kh√¥ng t√¨m th·∫•y c√¢u h·ªèi ho·∫∑c kh√¥ng c√≥ quy·ªÅn x√≥a.' });
    }

    return res.json({ message: 'ƒê√£ x√≥a th√†nh c√¥ng.' });
  } catch (error) {
    console.error('‚ùå L·ªói khi x√≥a c√¢u h·ªèi:', error);
    return res.status(500).json({ message: 'L·ªói server.' });
  }
}

// ==================== FUNCTIONS FROM RULES.JS ====================

/**
 * ·∫®n (m√£ h√≥a t·∫°m th·ªùi) c√°c th√¥ng tin nh·∫°y c·∫£m trong vƒÉn b·∫£n nh∆∞ s·ªë ƒëi·ªán tho·∫°i, email, ƒë·ªãa ch·ªâ.
 * Thay th·∫ø c√°c th√¥ng tin n√†y b·∫±ng c√°c placeholder (v√≠ d·ª•: [PHONE_1], [EMAIL_2], ...).
 * L∆∞u l·∫°i mapping gi·ªØa placeholder v√† gi√° tr·ªã g·ªëc ƒë·ªÉ c√≥ th·ªÉ kh√¥i ph·ª•c sau.
 * @param {string} text - VƒÉn b·∫£n c·∫ßn x·ª≠ l√Ω
 * @param {object} mapping - ƒê·ªëi t∆∞·ª£ng d√πng ƒë·ªÉ l∆∞u mapping gi·ªØa placeholder v√† gi√° tr·ªã g·ªëc
 * @returns {string} - VƒÉn b·∫£n ƒë√£ ƒë∆∞·ª£c thay th·∫ø th√¥ng tin nh·∫°y c·∫£m b·∫±ng placeholder
 */
export function maskSensitiveInfo(text, mapping = {}) {
  let counter = 1;
  // S·ªë ƒëi·ªán tho·∫°i
  text = text.replace(/\b\d{2,4}[-\s]?\d{3,4}[-\s]?\d{3,4}\b/g, (match) => {
    const key = `[PHONE_${counter++}]`;
    mapping[key] = match;
    return key;
  });
  // Email
  text = text.replace(
    /\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,}\b/gi,
    (match) => {
      const key = `[EMAIL_${counter++}]`;
      mapping[key] = match;
      return key;
    }
  );
  // ƒê·ªãa ch·ªâ (m·∫´u ƒë∆°n gi·∫£n, c√≥ th·ªÉ tu·ª≥ bi·∫øn th√™m)
  text = text.replace(
    /(\d{1,4}\s?[\w\s,./-]+(ƒë∆∞·ªùng|ph·ªë|t√≤a nh√†)[^\n,.]*)/gi,
    (match) => {
      const key = `[ADDR_${counter++}]`;
      mapping[key] = match;
      return key;
    }
  );
  return text;
}

/**
 * Kh√¥i ph·ª•c l·∫°i c√°c th√¥ng tin nh·∫°y c·∫£m ƒë√£ b·ªã m√£ h√≥a t·∫°m th·ªùi trong vƒÉn b·∫£n.
 * Thay th·∫ø c√°c placeholder (v√≠ d·ª•: [PHONE_1], [EMAIL_2], ...) b·∫±ng gi√° tr·ªã g·ªëc t·ª´ mapping.
 * @param {string} text - VƒÉn b·∫£n ch·ª©a c√°c placeholder
 * @param {object} mapping - ƒê·ªëi t∆∞·ª£ng mapping gi·ªØa placeholder v√† gi√° tr·ªã g·ªëc
 * @returns {string} - VƒÉn b·∫£n ƒë√£ ƒë∆∞·ª£c kh√¥i ph·ª•c th√¥ng tin nh·∫°y c·∫£m
 */
export function unmaskSensitiveInfo(text, mapping) {
  for (const [key, value] of Object.entries(mapping)) {
    text = text.replaceAll(key, value);
  }
  return text;
}

/**
 * G·ªçi API m√¥ h√¨nh ng√¥n ng·ªØ (OpenAI ho·∫∑c local), tr·∫£ v·ªÅ k·∫øt qu·∫£ ph·∫£n h·ªìi.
 * @param {string} model - T√™n m√¥ h√¨nh (gpt-4o, gpt-3.5, mistral, v.v.)
 * @param {Array} messages - Danh s√°ch messages theo ƒë·ªãnh d·∫°ng ChatML
 * @param {number} temperature - ƒê·ªô s√°ng t·∫°o
 * @param {number} maxTokens - Gi·ªõi h·∫°n tokens
 * @returns {string} - N·ªôi dung ph·∫£n h·ªìi
 */
export async function callLLM(
  model,
  messages,
  _temperature = 0.2,
  _maxTokens = 512
) {
  // Validate model
  if (!model || !model.url || !model.name) {
    throw new Error('Invalid model configuration: missing url or name');
  }

  const baseUrl = model.url;
  const nameModel = model.name;
  
  // Use temperature from model if available, otherwise use parameter
  const temperatureModel = model.temperature !== undefined ? model.temperature : _temperature;
  
  // Use maxTokens from model if available, otherwise use parameter
  const maxTokensModel = model.maxTokens !== undefined ? model.maxTokens : _maxTokens;

  // Normalize URL - remove trailing slash if exists
  const normalizedUrl = baseUrl.endsWith('/') ? baseUrl.slice(0, -1) : baseUrl;
  const fullUrl = `${normalizedUrl}/chat/completions`;

  console.log('üîó Calling LLM:', {
    url: fullUrl,
    model: nameModel,
    temperature: temperatureModel,
    max_tokens: maxTokensModel,
    messages_count: messages.length
  });

  try {
    const response = await axios.post(
      fullUrl,
      {
        model: nameModel,
        messages,
        temperature: temperatureModel,
        max_tokens: maxTokensModel,
      },
      {
        headers: {
          'Content-Type': 'application/json',
        },
        timeout: 180000, // 3 minutes timeout for complex RAG
      }
    );

    const content = response.data.choices[0].message.content.trim();
    console.log('‚úÖ LLM response received successfully');
    return content;
  } catch (error) {
    console.error('‚ùå LLM call error:', {
      message: error.message,
      response: error.response?.data,
      status: error.response?.status,
      url: fullUrl,
      request_body: {
        model: nameModel,
        temperature: temperatureModel,
        max_tokens: maxTokensModel,
        messages_count: messages.length
      }
    });
    throw new Error(`LLM API Error: ${error.message} - ${error.response?.data ? JSON.stringify(error.response.data) : ''}`);
  }
}

/**
 * G·ªçi OpenAI ChatGPT, cho ph√©p truy·ªÅn prompt h·ªá th·ªëng (systemPrompt) v√† ch·ªçn model.
 * H·ªó tr·ª£ m√£ h√≥a th√¥ng tin nh·∫°y c·∫£m tr∆∞·ªõc khi g·ª≠i l√™n AI v√† gi·∫£i m√£ sau khi nh·∫≠n k·∫øt qu·∫£.
 * @param {string} question - C√¢u h·ªèi t·ª´ user
 * @param {string} context - Context ki·∫øn th·ª©c tham kh·∫£o
 * @param {string} systemPrompt - Prompt h·ªá th·ªëng (t√πy ch·∫ø ƒë·ªô: tr·∫£ l·ªùi chu·∫©n, luy·ªán giao ti·∫øp, v.v.)
 * @param {string} model - T√™n model AI mu·ªën s·ª≠ d·ª•ng (m·∫∑c ƒë·ªãnh: 'gpt-4o')
 * @returns {Promise<string>} - N·ªôi dung tr·∫£ l·ªùi c·ªßa AI
 */
export async function askChatGPT(
  question,
  context,
  systemPrompt = 'B·∫°n l√† tr·ª£ l√Ω AI chuy√™n tr·∫£ l·ªùi d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p.',
  model
) {
  const mapping = {};

  // Mask th√¥ng tin nh·∫°y c·∫£m trong c√¢u h·ªèi
  const maskedQuestion = maskSensitiveInfo(question, mapping);

  let prompt = '';
  if (context && context.trim().length > 0) {
    // C√≥ context ‚Üí d·∫°ng RAG ho·∫∑c context-based
    const maskedContext = maskSensitiveInfo(context, mapping);
    prompt = `Th√¥ng tin tham kh·∫£o:\n${maskedContext}\n\nC√¢u h·ªèi: ${maskedQuestion}`;
  } else {
    // Kh√¥ng c√≥ context ‚Üí ch·∫ø ƒë·ªô "direct"
    prompt = maskedQuestion;
  }

  const messages = [
    { role: 'system', content: systemPrompt },
    { role: 'user', content: prompt },
  ];

  let reply = await callLLM(model, messages, 0.2, 512);

  // Unmask n·ªôi dung tr∆∞·ªõc khi tr·∫£ v·ªÅ
  reply = unmaskSensitiveInfo(reply, mapping);

  return reply;
}
