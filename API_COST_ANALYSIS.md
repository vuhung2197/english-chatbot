# Ph√¢n T√≠ch Chi Ph√≠ API v√† C√°ch T·ªëi ∆Øu H√≥a

## üí∞ C√ÅC API ƒêANG S·ª¨ D·ª§NG B·∫∞NG PH√ç (COST MONEY)

### üî¥ **1. OpenAI Embeddings API** - **T·ªêN PH√ç B·∫ÆT BU·ªòC**
**üìÅ Location**: `backend/services/embeddingVector.js`  
**üí∞ Chi ph√≠**: 
- Model `text-embedding-3-small`: **$0.02 per 1M tokens** (ƒë·∫ßu v√†o)
- R·∫ª nh·∫•t trong c√°c model embedding c·ªßa OpenAI
- V√≠ d·ª•: 10,000 c√¢u h·ªèi ‚âà 500,000 tokens ‚âà **$0.01**

**T·∫ßn su·∫•t**: **M·ªñI c√¢u h·ªèi** ƒë·ªÅu g·ªçi API n√†y  
**Kh√¥ng th·ªÉ tr√°nh**: ƒê√¢y l√† l√µi c·ªßa RAG system, c·∫ßn ƒë·ªÉ t√¨m semantic similarity

**C√°ch t·ªëi ∆∞u**:
- ‚úÖ Cache embeddings cho c√¢u h·ªèi t∆∞∆°ng t·ª±
- ‚úÖ Batch multiple questions c√πng l√∫c
- ‚ö†Ô∏è Kh√≥ thay th·∫ø ho√†n to√†n (c·∫ßn model embedding kh√°c)

---

### üî¥ **2. OpenAI Chat/Completion APIs** - **T·ªêN PH√ç T√ôY CH·ªåN**

#### A. OpenAI Chat Completions (cho Chat Response)
**üìÅ Location**: Khi `model.url` l√† `https://api.openai.com`  
**üí∞ Chi ph√≠**:
- GPT-4 Turbo: **$10-30 per 1M input tokens**, **$30 per 1M output tokens**
- GPT-3.5 Turbo: **$0.50-1.5 per 1M input tokens**, **$2 per 1M output tokens**

**T·∫ßn su·∫•t**: M·ªói c√¢u h·ªèi (n·∫øu d√πng OpenAI model)  
**Khi n√†o t·ªën ph√≠**:
- ‚úÖ N·∫øu ch·ªçn OpenAI model t·ª´ Model Manager
- ‚ùå N·∫øu ch·ªçn Ollama local ‚Üí **MI·ªÑN PH√ç**

#### B. OpenAI Completions (cho Word Suggestions)
**üìÅ Location**: `backend/controllers/suggestController.js`  
**üí∞ Chi ph√≠**: 
- GPT-3.5-turbo-instruct: **$1.5 per 1M input tokens**, **$2 per 1M output tokens**

**T·∫ßn su·∫•t**: T√πy ch·ªçn (khi user d√πng autocomplete)  
**T√≠nh nƒÉng**: Kh√¥ng c·∫ßn thi·∫øt, c√≥ th·ªÉ t·∫Øt

#### C. OpenAI Chat Completions (cho Translations)
**üìÅ Location**: `backend/controllers/chatController.js` (translateSingleWord)  
**üí∞ Chi ph√≠**: GPT-4o - **$2.5-$10 per 1M tokens** (t√πy input/output)

**T·∫ßn su·∫•t**: T√πy ch·ªçn (khi d·ªãch t·ª´)  
**T√≠nh nƒÉng**: Kh√¥ng c·∫ßn thi·∫øt, √≠t khi ƒë∆∞·ª£c g·ªçi

---

## üü¢ **3. Ollama Local LLM** - **MI·ªÑN PH√ç**

**üìÅ Location**: Khi `model.url` l√† `http://localhost:11434` ho·∫∑c local Ollama server  
**üí∞ Chi ph√≠**: **$0** (ch·∫°y local tr√™n m√°y c·ªßa b·∫°n)

**T·∫ßn su·∫•t**: M·ªói c√¢u h·ªèi (n·∫øu d√πng Ollama)  
**C√°ch s·ª≠ d·ª•ng**: 
1. C√†i ƒë·∫∑t Ollama: `ollama install llama3.2`
2. Trong Model Manager, th√™m model v·ªõi URL: `http://localhost:11434`
3. Ch·ªçn model ƒë√≥ ‚Üí **KH√îNG T·ªêN PH√ç**

---

## üìä T·ªîNG K·∫æT CHI PH√ç

### Scenario 1: D√πng 100% OpenAI
```
M·ªói c√¢u h·ªèi:
- OpenAI Embeddings: ~$0.00001 (r·∫•t r·∫ª)
- OpenAI Chat (GPT-4o): ~$0.01-0.03 (ƒë·∫Øt!)
T·ªïng: ~$0.02 per c√¢u h·ªèi
100 c√¢u h·ªèi = $2-3
```

### Scenario 2: Ollama + OpenAI Embeddings (KHUY·∫æN NGH·ªä)
```
M·ªói c√¢u h·ªèi:
- OpenAI Embeddings: ~$0.00001 (r·∫•t r·∫ª)
- Ollama LLM: $0 (mi·ªÖn ph√≠)
T·ªïng: ~$0.00001 per c√¢u h·ªèi
10,000 c√¢u h·ªèi = ~$0.10
```

### Scenario 3: 100% Local (kh√≥ khƒÉn)
```
Y√™u c·∫ßu: Thay th·∫ø OpenAI Embeddings b·∫±ng model local
Chi ph√≠: $0
Kh√≥ khƒÉn: C·∫ßn c√†i ƒë·∫∑t embedding model (v√≠ d·ª•: BGE-large-en-v1.5)
```

---

## üéØ KHUY·∫æN NGH·ªä T·ªêI ∆ØU CHI PH√ç

### ‚úÖ **N√™n l√†m**:

1. **S·ª≠ d·ª•ng Ollama cho Chat Response** ‚≠ê‚≠ê‚≠ê
   - Gi·∫£m 99% chi ph√≠ API
   - Ch·∫•t l∆∞·ª£ng v·∫´n t·ªët v·ªõi LLaMA 3.2, Mistral 7B
   - H∆∞·ªõng d·∫´n:
     ```bash
     # C√†i ƒë·∫∑t Ollama
     curl -fsSL https://ollama.ai/install.sh | sh
     
     # C√†i model (ch·ªçn 1)
     ollama pull llama3.2        # Nh·∫π, nhanh
     ollama pull mistral:7b      # T·ªët, v·ª´a
     ollama pull codellama:7b    # M·∫°nh cho code
     
     # Trong Model Manager, th√™m:
     Name: Local LLaMA
     URL: http://localhost:11434
     Model: llama3.2
     ```

2. **Gi·ªØ l·∫°i OpenAI Embeddings** ‚≠ê‚≠ê‚≠ê
   - R·∫ª nh·∫•t: $0.02 per 1M tokens
   - Ch·∫•t l∆∞·ª£ng t·ªët
   - Kh√≥ thay th·∫ø

3. **T·∫Øt c√°c t√≠nh nƒÉng kh√¥ng c·∫ßn thi·∫øt**:
   - Word Suggestions (t·ªën ph√≠ nh∆∞ng √≠t d√πng)
   - Translations (c√≥ th·ªÉ b·ªè)
   - Code:
     ```javascript
     // ƒê·ªÉ t·∫Øt suggestions, x√≥a ho·∫∑c comment
     // backend/controllers/suggestController.js
     ```

4. **Cache Embeddings**:
   - L∆∞u embeddings c·ªßa c√¢u h·ªèi t∆∞∆°ng t·ª±
   - Tr√°nh g·ªçi l·∫°i API cho c√¢u h·ªèi ƒë√£ tr·∫£ l·ªùi
   - Ti·∫øt ki·ªám ~30-50% chi ph√≠ embeddings

5. **Monitor API Usage**:
   - Check OpenAI dashboard th∆∞·ªùng xuy√™n
   - Set budget alerts
   - Track s·ªë l∆∞·ª£ng requests

### ‚ùå **Kh√¥ng n√™n**:

1. **D√πng GPT-4 Turbo cho production** (tr·ª´ khi c√≥ budget l·ªõn)
   - ƒê·∫Øt 10-20x so v·ªõi GPT-3.5
   - Ch·ªâ d√πng khi c·∫ßn ƒë·ªô ch√≠nh x√°c c·ª±c cao

2. **Kh√¥ng cache b·∫•t c·ª© g√¨**
   - TƒÉng chi ph√≠ kh√¥ng c·∫ßn thi·∫øt

3. **D√πng OpenAI cho t·∫•t c·∫£**
   - Chi ph√≠ r·∫•t cao n·∫øu user base l·ªõn

---

## üìà ∆Ø·ªöC T√çNH CHI PH√ç THEO USAGE

### 10 ng∆∞·ªùi d√πng, m·ªói ng∆∞·ªùi 50 c√¢u h·ªèi/th√°ng:
```
Scenario OpenAI: ~$10-20/th√°ng
Scenario Ollama + Embeddings: ~$0.10/th√°ng
```

### 100 ng∆∞·ªùi d√πng, m·ªói ng∆∞·ªùi 100 c√¢u h·ªèi/th√°ng:
```
Scenario OpenAI: ~$200-400/th√°ng
Scenario Ollama + Embeddings: ~$1/th√°ng
```

### 1000 ng∆∞·ªùi d√πng:
```
Scenario OpenAI: ~$2000-4000/th√°ng
Scenario Ollama + Embeddings: ~$10/th√°ng
```

---

## üöÄ H∆Ø·ªöNG D·∫™N SETUP OLLAMA (MI·ªÑN PH√ç)

### B∆∞·ªõc 1: C√†i ƒë·∫∑t Ollama
```bash
# Linux/Mac
curl -fsSL https://ollama.ai/install.sh | sh

# Windows: Download t·ª´ https://ollama.ai/download
```

### B∆∞·ªõc 2: Pull model
```bash
ollama pull llama3.2  # Model nh·∫π, nhanh
# ho·∫∑c
ollama pull mistral    # Model t·ªët h∆°n
```

### B∆∞·ªõc 3: Th√™m v√†o Model Manager
1. M·ªü Chat interface
2. Click "Qu·∫£n l√Ω Model" button
3. Th√™m model m·ªõi:
   - Name: `Local LLaMA`
   - URL: `http://localhost:11434`
   - Model: `llama3.2`
   - Temperature: `0.7`
   - MaxTokens: `1024`
4. Click "Ch·ªçn model n√†y"

### B∆∞·ªõc 4: Test
- G·ª≠i m·ªôt c√¢u h·ªèi test
- Ki·ªÉm tra console log: `üîó Calling LLM: { url: 'http://localhost:11434/chat/completions' }`
- N·∫øu th·∫•y log n√†y ‚Üí ƒêang d√πng Ollama (mi·ªÖn ph√≠)

---

## üõ°Ô∏è B·∫¢O V·ªÜ NG√ÇN S√ÅCH

### 1. Set Usage Limits trong OpenAI Dashboard:
```
Settings ‚Üí Organization ‚Üí Usage Limits
- Hard Limit: $50/th√°ng (warning khi t·ªõi $45)
- Soft Limit: $30/th√°ng
```

### 2. Monitor:
```javascript
// Th√™m v√†o backend ƒë·ªÉ log usage
console.log('üí∞ Total OpenAI cost this hour:', calculateCost());
```

### 3. Block ƒë√∫ng l√∫c:
- N·∫øu v∆∞·ª£t qu√° budget ‚Üí switch to Ollama
- Alert khi cost > threshold

---

## üìå T√ìM T·∫ÆT

| API | Chi Ph√≠ | T·∫ßn Su·∫•t | C√≥ th·ªÉ tr√°nh? | Khuy·∫øn ngh·ªã |
|-----|---------|----------|--------------|-------------|
| **OpenAI Embeddings** | $0.02/1M tokens | M·ªói c√¢u h·ªèi | ‚ùå Kh√≥ | ‚úÖ Gi·ªØ l·∫°i |
| **OpenAI Chat (GPT-4)** | $2.5-30/1M tokens | M·ªói c√¢u h·ªèi | ‚úÖ C√≥ | ‚ùå Qu√° ƒë·∫Øt |
| **OpenAI Chat (GPT-3.5)** | $0.5-2/1M tokens | M·ªói c√¢u h·ªèi | ‚úÖ C√≥ | ‚ö†Ô∏è T·∫°m th·ªùi |
| **Ollama Local** | $0 | M·ªói c√¢u h·ªèi | - | ‚úÖ **KHUY·∫æN NGH·ªä** |
| Word Suggestions | ~$1.5/1M tokens | T√πy ch·ªçn | ‚úÖ C√≥ | ‚ùå T·∫Øt ƒëi |
| Translations | ~$2.5/1M tokens | T√πy ch·ªçn | ‚úÖ C√≥ | ‚ùå T·∫Øt ƒëi |

---

**üí° K·∫æT LU·∫¨N**:
- **Chi ph√≠ ch√≠nh**: OpenAI Embeddings (~$0.00001/c√¢u) + ChatGPT Response (~$0.01-0.03/c√¢u n·∫øu d√πng OpenAI)
- **Gi·∫£i ph√°p t·ªët nh·∫•t**: Ollama cho chat + OpenAI cho embeddings
- **Ti·∫øt ki·ªám**: 99% chi ph√≠ so v·ªõi d√πng 100% OpenAI

**T·∫°o b·ªüi**: AI Assistant  
**Ng√†y**: $(date)  
**Version**: 1.0

